{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows some of the most used techniques to transform the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/snap/jupyter/common/lib/python3.7/site-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    data = arff.loadarff(data_path)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_kdd_dataset(\"../datasets/NSL-KDD/KDDTrain+.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'ftp_data'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'udp'</td>\n",
       "      <td>b'other'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'private'</td>\n",
       "      <td>b'S0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'anomaly'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>232.0</td>\n",
       "      <td>8153.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>199.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'private'</td>\n",
       "      <td>b'S0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'anomaly'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>8.0</td>\n",
       "      <td>b'udp'</td>\n",
       "      <td>b'private'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>105.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'smtp'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>2231.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'klogin'</td>\n",
       "      <td>b'S0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'anomaly'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'ftp_data'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b'normal'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration protocol_type      service   flag  src_bytes  dst_bytes  \\\n",
       "0            0.0        b'tcp'  b'ftp_data'  b'SF'      491.0        0.0   \n",
       "1            0.0        b'udp'     b'other'  b'SF'      146.0        0.0   \n",
       "2            0.0        b'tcp'   b'private'  b'S0'        0.0        0.0   \n",
       "3            0.0        b'tcp'      b'http'  b'SF'      232.0     8153.0   \n",
       "4            0.0        b'tcp'      b'http'  b'SF'      199.0      420.0   \n",
       "...          ...           ...          ...    ...        ...        ...   \n",
       "125968       0.0        b'tcp'   b'private'  b'S0'        0.0        0.0   \n",
       "125969       8.0        b'udp'   b'private'  b'SF'      105.0      145.0   \n",
       "125970       0.0        b'tcp'      b'smtp'  b'SF'     2231.0      384.0   \n",
       "125971       0.0        b'tcp'    b'klogin'  b'S0'        0.0        0.0   \n",
       "125972       0.0        b'tcp'  b'ftp_data'  b'SF'      151.0        0.0   \n",
       "\n",
       "        land  wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0       b'0'             0.0     0.0  0.0  ...                25.0   \n",
       "1       b'0'             0.0     0.0  0.0  ...                 1.0   \n",
       "2       b'0'             0.0     0.0  0.0  ...                26.0   \n",
       "3       b'0'             0.0     0.0  0.0  ...               255.0   \n",
       "4       b'0'             0.0     0.0  0.0  ...               255.0   \n",
       "...      ...             ...     ...  ...  ...                 ...   \n",
       "125968  b'0'             0.0     0.0  0.0  ...                25.0   \n",
       "125969  b'0'             0.0     0.0  0.0  ...               244.0   \n",
       "125970  b'0'             0.0     0.0  0.0  ...                30.0   \n",
       "125971  b'0'             0.0     0.0  0.0  ...                 8.0   \n",
       "125972  b'0'             0.0     0.0  0.0  ...                77.0   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                        0.17                    0.03   \n",
       "1                        0.00                    0.60   \n",
       "2                        0.10                    0.05   \n",
       "3                        1.00                    0.00   \n",
       "4                        1.00                    0.00   \n",
       "...                       ...                     ...   \n",
       "125968                   0.10                    0.06   \n",
       "125969                   0.96                    0.01   \n",
       "125970                   0.12                    0.06   \n",
       "125971                   0.03                    0.05   \n",
       "125972                   0.30                    0.03   \n",
       "\n",
       "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                              0.17                         0.00   \n",
       "1                              0.88                         0.00   \n",
       "2                              0.00                         0.00   \n",
       "3                              0.03                         0.04   \n",
       "4                              0.00                         0.00   \n",
       "...                             ...                          ...   \n",
       "125968                         0.00                         0.00   \n",
       "125969                         0.01                         0.00   \n",
       "125970                         0.00                         0.00   \n",
       "125971                         0.00                         0.00   \n",
       "125972                         0.30                         0.00   \n",
       "\n",
       "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                       0.00                      0.00                  0.05   \n",
       "1                       0.00                      0.00                  0.00   \n",
       "2                       1.00                      1.00                  0.00   \n",
       "3                       0.03                      0.01                  0.00   \n",
       "4                       0.00                      0.00                  0.00   \n",
       "...                      ...                       ...                   ...   \n",
       "125968                  1.00                      1.00                  0.00   \n",
       "125969                  0.00                      0.00                  0.00   \n",
       "125970                  0.72                      0.00                  0.01   \n",
       "125971                  1.00                      1.00                  0.00   \n",
       "125972                  0.00                      0.00                  0.00   \n",
       "\n",
       "        dst_host_srv_rerror_rate       class  \n",
       "0                           0.00   b'normal'  \n",
       "1                           0.00   b'normal'  \n",
       "2                           0.00  b'anomaly'  \n",
       "3                           0.01   b'normal'  \n",
       "4                           0.00   b'normal'  \n",
       "...                          ...         ...  \n",
       "125968                      0.00  b'anomaly'  \n",
       "125969                      0.00   b'normal'  \n",
       "125970                      0.00   b'normal'  \n",
       "125971                      0.00  b'anomaly'  \n",
       "125972                      0.00   b'normal'  \n",
       "\n",
       "[125973 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Splitting of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = train_val_test_split(df, stratify='protocol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Length: 75583\n",
      "Validation Set Length: 25195\n",
      "Test Set Length: 25195\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Length:\", len(train_set))\n",
    "print(\"Validation Set Length:\", len(val_set))\n",
    "print(\"Test Set Length:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's retrieve the clean dataset and separate the labels from the rest of the data, we don't necessarily want to apply the same transformations on both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We separate the input features from the output feature\n",
    "X_train = train_set.drop(\"class\", axis=1)\n",
    "y_train = train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To illustrate this section we are going to add some null values to some features of the dataset\n",
    "X_train.loc[(X_train[\"src_bytes\"]>400) & (X_train[\"src_bytes\"]<800), \"src_bytes\"] = np.nan\n",
    "X_train.loc[(X_train[\"dst_bytes\"]>500) & (X_train[\"dst_bytes\"]<2000), \"dst_bytes\"] = np.nan\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most machine learning algorithms cannot work on features that contain null values. Therefore, there are three options to replace them:  \n",
    "\n",
    "* Delete the corresponding rows\n",
    "* Delete the corresponding attribute (column)\n",
    "* Fill them with a given value (zero, mean...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any attribute with null values\n",
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows that contain null values\n",
    "filas_valores_nulos  = X_train[X_train.isnull().any(axis=1)]\n",
    "filas_valores_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: We delete the rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We copy the dataset so as not to alter the original\n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with null values\n",
    "X_train_copy.dropna(subset=[\"src_bytes\", \"dst_bytes\"], inplace=True)\n",
    "X_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows deleted\n",
    "print(\"The number of rows removed is:\", len(X_train) - len(X_train_copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: We remove the attributes with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We copy the dataset so as not to alter the original\n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove attributes with null values\n",
    "X_train_copy.drop([\"src_bytes\", \"dst_bytes\"], axis=1, inplace=True)\n",
    "X_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of attributes removed\n",
    "print(\"The number of attributes removed is:\", len(list(X_train)) - len(list(X_train_copy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3: We fill the null values with a certain value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We copy the dataset so as not to alter the original\n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill the null values with the average of the attribute values\n",
    "media_srcbytes = X_train_copy[\"src_bytes\"].mean()\n",
    "media_dstbytes = X_train_copy[\"dst_bytes\"].mean()\n",
    "\n",
    "X_train_copy[\"src_bytes\"].fillna(media_srcbytes, inplace=True)\n",
    "X_train_copy[\"dst_bytes\"].fillna(media_dstbytes, inplace=True)\n",
    "\n",
    "X_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We copy the dataset so as not to alter the original\n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very high value in the attribute can trigger the average\n",
    "# Fill the values with the median\n",
    "mediana_srcbytes = X_train_copy[\"src_bytes\"].median()\n",
    "mediana_dstbytes = X_train_copy[\"dst_bytes\"].median()\n",
    "\n",
    "X_train_copy[\"src_bytes\"].fillna(mediana_srcbytes, inplace=True)\n",
    "X_train_copy[\"dst_bytes\"].fillna(mediana_dstbytes, inplace=True)\n",
    "\n",
    "X_train_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is another alternative to option 3 which is to use sklearn's Imputer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We copy the dataset so as not to alter the original\n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imputer class does not support categorical values, we remove the categorical attributes\n",
    "X_train_copy_num = X_train_copy.select_dtypes(exclude=['object'])\n",
    "X_train_copy_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical attributes are provided for you to calculate the values\n",
    "imputer.fit(X_train_copy_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the null values\n",
    "X_train_copy_num_nonan = imputer.transform(X_train_copy_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform the result to a Pandas DataFrame\n",
    "X_train_copy = pd.DataFrame(X_train_copy_num_nonan, columns=X_train_copy_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Estimators**: Any object that can estimate some parameter:  \n",
    "    * The estimator itself is formed by the fit() method, which always takes a dataset as an argument.  \n",
    "    * Any other parameter of this method is a hyperparameter.  \n",
    "* **Transformers**: They are estimators capable of transforming the data set (as Inputer).  \n",
    "    * The transformation is done using the transform() method.  \n",
    "    * Reciben un dataset como parámetro de entrada.  \n",
    "* **Predictors**: They are estimators capable of making predictions.  \n",
    "    * Prediction is done using the predict() method.\n",
    "    * Reciben un dataset como entrada.\n",
    "    * Retornan un dataset con las predicciones.\n",
    "    * They have a score() method to evaluate the result of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Transformation of categorical attributes to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(\"class\", axis=1)\n",
    "y_train = train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning algorithms generally ingest numerical data. In our data set we have a lot of categorical values and therefore we need to convert them to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to convert categorical attributes to numeric. Probably the simplest is the one provided by Pandas' **factorize** method. Which transforms each category into a sequential number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_type = X_train['protocol_type']\n",
    "protocol_type_encoded, categorias = protocol_type.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We show on the screen how they have been encoded\n",
    "for i in range(10):\n",
    "    print(protocol_type.iloc[i], \"=\", protocol_type_encoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categorias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced transformations using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ordinal Encoding  \n",
    "Performs the same encoding as Pandas' **factorize** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "protocol_type = X_train[['protocol_type']]\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "protocol_type_encoded = ordinal_encoder.fit_transform(protocol_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We show on the screen how they have been encoded\n",
    "for i in range(10):\n",
    "    print(protocol_type[\"protocol_type\"].iloc[i], \"=\", protocol_type_encoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this type of encoding is that certain ML algorithms that work by measuring the similarity of two points by distance will consider that 1 is closer to 2 than to 3, and in this case (for these categorical values) , Has no sense. Therefore, other categorization methods are used, such as One-Hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-Hot Encoding  \n",
    "Generates for each category of the categorical attribute a binary matrix that represents the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sparse matrix only stores the position of values that are not '0' to save memory\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "protocol_type = X_train[['protocol_type']]\n",
    "\n",
    "oh_encoder = OneHotEncoder()\n",
    "protocol_type_oh = oh_encoder.fit_transform(protocol_type)\n",
    "protocol_type_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a Numpy array\n",
    "protocol_type_oh.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We show on the screen how they have been encoded\n",
    "for i in range(10):\n",
    "    print(protocol_type[\"protocol_type\"].iloc[i], \"=\", protocol_type_oh.toarray()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On many occasions, when partitioning the data set or when making a prediction with new examples, new values appear for certain categories that will produce an error in the transform() function. The OneHotEncoding class provides the handle_uknown parameter to either raise an error or ignore if an unknown categorical feature is present during the transformation (default is to throw an error).  \n",
    "\n",
    "When this parameter is set to \"ignore\" and an unknown category is encountered during the transformation, the resulting encoded columns for this feature will be all zeros. In the reverse transformation, an unknown category will be denoted as None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Dummies  \n",
    "Get Dummies is an easy to use method that allows you to apply One-Hot Encoding to a Pandas Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(X_train['protocol_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dataset Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(\"class\", axis=1)\n",
    "y_train = train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general rule, Machine Learning algorithms do not behave properly if the values of the features they receive as input are in very different ranges. Therefore, different scaling techniques are used. It is important to note that these scaling mechanisms should not be applied to labels.  \n",
    "* **Normalization**: The attribute values are scaled to acquire a value between 0 and 1.  \n",
    "* **Standardization**: The attribute values are scaled and receive a similar value but it is not within a range.  \n",
    "\n",
    "***It is important that to test these values, the transformations are performed only on the training data set. Then, they will be applied on the test data set to test.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scale_attrs = X_train[['src_bytes', 'dst_bytes']]\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_scaled = robust_scaler.fit_transform(scale_attrs)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=['src_bytes', 'dst_bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
